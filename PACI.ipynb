{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f634290",
   "metadata": {},
   "source": [
    "# Proyecto de Machine Learning: Gu√≠a Completa desde la Recepci√≥n de Datos\n",
    "\n",
    "## 1. Introducci√≥n al Proyecto y Definici√≥n del Problema de Negocio\n",
    "\n",
    "### Objetivo de esta secci√≥n\n",
    "Presentar el proyecto y vincular el problema de negocio con un problema de Machine Learning. Es crucial entender el problema antes de proponer una soluci√≥n.\n",
    "\n",
    "### 1.1 Definici√≥n del Problema Empresarial\n",
    "\n",
    "En este notebook, trabajaremos con un ejemplo pr√°ctico: **Predicci√≥n de abandono de clientes (Churn)** en una empresa de telecomunicaciones. \n",
    "\n",
    "El problema de negocio es el siguiente:\n",
    "- La empresa est√° perdiendo aproximadamente 26% de sus clientes anualmente\n",
    "- Adquirir un nuevo cliente cuesta 5x m√°s que retener uno existente\n",
    "- Necesitamos identificar clientes en riesgo de abandono para tomar acciones preventivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as necesarias para todo el proyecto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n del problema en t√©rminos de ML\n",
    "problema_ml = {\n",
    "    'tipo': 'Clasificaci√≥n Binaria',\n",
    "    'variable_objetivo': 'Churn',\n",
    "    'clases': ['No abandona (0)', 'Abandona (1)'],\n",
    "    'enfoque': 'Aprendizaje Supervisado',\n",
    "    'metricas_clave': ['Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "}\n",
    "\n",
    "print(\"=== DEFINICI√ìN DEL PROBLEMA DE ML ===\")\n",
    "for key, value in problema_ml.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Definici√≥n de criterios de √©xito\n",
    "criterios_exito = {\n",
    "    'ml_metrics': {\n",
    "        'precision_minima': 0.85,\n",
    "        'f1_score_minimo': 0.82\n",
    "    },\n",
    "    'business_metrics': {\n",
    "        'reduccion_churn_esperada': '15%',\n",
    "        'tiempo_implementacion': '3 meses'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== CRITERIOS DE √âXITO ===\")\n",
    "print(\"\\nM√©tricas de Machine Learning:\")\n",
    "for metric, value in criterios_exito['ml_metrics'].items():\n",
    "    print(f\"  - {metric}: {value}\")\n",
    "print(\"\\nM√©tricas de Negocio:\")\n",
    "for metric, value in criterios_exito['business_metrics'].items():\n",
    "    print(f\"  - {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a11cd",
   "metadata": {},
   "source": [
    "## 2. Adquisici√≥n y An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "### Objetivo de esta secci√≥n\n",
    "Entender la naturaleza de los datos recibidos, identificar patrones, anomal√≠as y preparar el terreno para el preprocesamiento.\n",
    "\n",
    "### 2.1 Recopilaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f220cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulaci√≥n de carga de datos (en un caso real, cargar√≠as desde tu fuente)\n",
    "# Para este ejemplo, crearemos un dataset sint√©tico representativo\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "# Generaci√≥n de datos sint√©ticos de clientes de telecomunicaciones\n",
    "data = {\n",
    "    'CustomerID': range(1, n_samples + 1),\n",
    "    'Tenure': np.random.randint(0, 72, n_samples),  # Meses como cliente\n",
    "    'MonthlyCharges': np.random.uniform(20, 120, n_samples),\n",
    "    'TotalCharges': np.random.uniform(100, 8000, n_samples),\n",
    "    'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples, p=[0.5, 0.25, 0.25]),\n",
    "    'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_samples),\n",
    "    'PaperlessBilling': np.random.choice(['Yes', 'No'], n_samples),\n",
    "    'OnlineSecurity': np.random.choice(['Yes', 'No', 'No internet'], n_samples),\n",
    "    'TechSupport': np.random.choice(['Yes', 'No', 'No internet'], n_samples),\n",
    "    'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples, p=[0.4, 0.4, 0.2]),\n",
    "    'PhoneService': np.random.choice(['Yes', 'No'], n_samples, p=[0.9, 0.1]),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'SeniorCitizen': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),\n",
    "    'Partner': np.random.choice(['Yes', 'No'], n_samples),\n",
    "    'Dependents': np.random.choice(['Yes', 'No'], n_samples, p=[0.3, 0.7])\n",
    "}\n",
    "\n",
    "# Variable objetivo con correlaci√≥n realista\n",
    "churn_probability = []\n",
    "for i in range(n_samples):\n",
    "    prob = 0.15  # Probabilidad base\n",
    "    if data['Contract'][i] == 'Month-to-month':\n",
    "        prob += 0.3\n",
    "    if data['Tenure'][i] < 12:\n",
    "        prob += 0.2\n",
    "    if data['MonthlyCharges'][i] > 80:\n",
    "        prob += 0.1\n",
    "    if data['TechSupport'][i] == 'No':\n",
    "        prob += 0.1\n",
    "    churn_probability.append(min(prob, 0.9))\n",
    "\n",
    "data['Churn'] = np.random.binomial(1, churn_probability)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"=== INFORMACI√ìN DEL DATASET ===\")\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"N√∫mero de clientes: {df.shape[0]}\")\n",
    "print(f\"N√∫mero de caracter√≠sticas: {df.shape[1] - 1}\")  # -1 por la variable objetivo\n",
    "print(f\"\\nPrimeras 5 filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de tipos de datos\n",
    "print(\"=== TIPOS DE DATOS ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Informaci√≥n general del dataset\n",
    "print(\"\\n=== INFORMACI√ìN GENERAL DEL DATASET ===\")\n",
    "df.info()\n",
    "\n",
    "# Identificaci√≥n de caracter√≠sticas num√©ricas y categ√≥ricas\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCaracter√≠sticas num√©ricas ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"Caracter√≠sticas categ√≥ricas ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Estad√≠sticas descriptivas para variables num√©ricas\n",
    "print(\"\\n=== ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES NUM√âRICAS ===\")\n",
    "df[numerical_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de la variable objetivo\n",
    "print(\"=== DISTRIBUCI√ìN DE LA VARIABLE OBJETIVO (CHURN) ===\")\n",
    "churn_dist = df['Churn'].value_counts()\n",
    "churn_pct = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Conteo absoluto:\")\n",
    "print(churn_dist)\n",
    "print(\"\\nPorcentaje:\")\n",
    "print(churn_pct)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['Churn'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribuci√≥n de Churn')\n",
    "plt.xlabel('Churn (0 = No, 1 = S√≠)')\n",
    "plt.ylabel('Cantidad de clientes')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Verificar si hay desbalance de clases\n",
    "if churn_pct.min() < 20:\n",
    "    print(\"\\n‚ö†Ô∏è ADVERTENCIA: Dataset desbalanceado detectado. Considerar t√©cnicas de balanceo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6964646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n para variables num√©ricas\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlaci√≥n - Variables Num√©ricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de distribuciones por variable objetivo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Tenure vs Churn\n",
    "axes[0, 0].hist([df[df['Churn']==0]['Tenure'], df[df['Churn']==1]['Tenure']], \n",
    "                label=['No Churn', 'Churn'], bins=20, alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Tenure (meses)')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].set_title('Distribuci√≥n de Tenure por Churn')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# MonthlyCharges vs Churn\n",
    "axes[0, 1].hist([df[df['Churn']==0]['MonthlyCharges'], df[df['Churn']==1]['MonthlyCharges']], \n",
    "                label=['No Churn', 'Churn'], bins=20, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Cargos Mensuales')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].set_title('Distribuci√≥n de Cargos Mensuales por Churn')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Contract type vs Churn\n",
    "contract_churn = pd.crosstab(df['Contract'], df['Churn'], normalize='index') * 100\n",
    "contract_churn.plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Tasa de Churn por Tipo de Contrato')\n",
    "axes[1, 0].set_ylabel('Porcentaje (%)')\n",
    "axes[1, 0].set_xlabel('Tipo de Contrato')\n",
    "axes[1, 0].legend(['No Churn', 'Churn'])\n",
    "\n",
    "# PaymentMethod vs Churn\n",
    "payment_churn = pd.crosstab(df['PaymentMethod'], df['Churn'], normalize='index') * 100\n",
    "payment_churn.plot(kind='bar', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Tasa de Churn por M√©todo de Pago')\n",
    "axes[1, 1].set_ylabel('Porcentaje (%)')\n",
    "axes[1, 1].set_xlabel('M√©todo de Pago')\n",
    "axes[1, 1].legend(['No Churn', 'Churn'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de valores faltantes\n",
    "print(\"=== AN√ÅLISIS DE VALORES FALTANTES ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Columna': missing_values.index,\n",
    "    'Valores_Faltantes': missing_values.values,\n",
    "    'Porcentaje': missing_percentage.values\n",
    "})\n",
    "\n",
    "print(missing_df[missing_df['Valores_Faltantes'] > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"‚úÖ No se encontraron valores faltantes en el dataset\")\n",
    "\n",
    "# Verificaci√≥n de duplicados\n",
    "print(\"\\n=== AN√ÅLISIS DE DUPLICADOS ===\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"N√∫mero de filas duplicadas: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"Porcentaje de duplicados: {(duplicates/len(df))*100:.2f}%\")\n",
    "else:\n",
    "    print(\"‚úÖ No se encontraron registros duplicados\")\n",
    "\n",
    "# Detecci√≥n de outliers usando el m√©todo IQR\n",
    "print(\"\\n=== DETECCI√ìN DE OUTLIERS ===\")\n",
    "\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# An√°lisis de outliers para variables num√©ricas clave\n",
    "for col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  - L√≠mite inferior: {lower:.2f}\")\n",
    "    print(f\"  - L√≠mite superior: {upper:.2f}\")\n",
    "    print(f\"  - N√∫mero de outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76710193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de outliers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for idx, col in enumerate(['Tenure', 'MonthlyCharges', 'TotalCharges']):\n",
    "    df.boxplot(column=col, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e82c8",
   "metadata": {},
   "source": [
    "## 3. Ingenier√≠a de Caracter√≠sticas (Feature Engineering) y Preprocesamiento\n",
    "\n",
    "### Objetivo de esta secci√≥n\n",
    "Transformar los datos crudos en un formato que sea m√°s adecuado para el modelado de Machine Learning, mejorando el rendimiento y la robustez del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del dataset para preprocesamiento\n",
    "df_preprocessed = df.copy()\n",
    "\n",
    "print(\"‚úÖ Limpieza de datos completada\")\n",
    "\n",
    "# Feature Engineering: Crear nuevas caracter√≠sticas basadas en conocimiento del dominio\n",
    "\n",
    "# 1. Ratio de cargos totales sobre tenure (gasto promedio mensual real)\n",
    "df_preprocessed['AvgChargesPerMonth'] = np.where(\n",
    "    df_preprocessed['Tenure'] > 0,\n",
    "    df_preprocessed['TotalCharges'] / df_preprocessed['Tenure'],\n",
    "    df_preprocessed['MonthlyCharges']\n",
    ")\n",
    "\n",
    "# 2. Categorizaci√≥n de tenure\n",
    "df_preprocessed['TenureCategory'] = pd.cut(\n",
    "    df_preprocessed['Tenure'],\n",
    "    bins=[0, 12, 24, 48, 72],\n",
    "    labels=['Nuevo', 'Regular', 'Establecido', 'Leal']\n",
    ")\n",
    "\n",
    "# 3. Indicador de servicio premium\n",
    "df_preprocessed['PremiumServices'] = (\n",
    "    (df_preprocessed['OnlineSecurity'] == 'Yes').astype(int) +\n",
    "    (df_preprocessed['TechSupport'] == 'Yes').astype(int)\n",
    ")\n",
    "\n",
    "# 4. Indicador de cliente de alto valor\n",
    "high_value_threshold = df_preprocessed['MonthlyCharges'].quantile(0.75)\n",
    "df_preprocessed['HighValueCustomer'] = (\n",
    "    df_preprocessed['MonthlyCharges'] > high_value_threshold\n",
    ").astype(int)\n",
    "\n",
    "# 5. Indicador de compromiso (contrato largo + sin factura en papel)\n",
    "df_preprocessed['EngagementScore'] = 0\n",
    "df_preprocessed.loc[df_preprocessed['Contract'] == 'Two year', 'EngagementScore'] += 2\n",
    "df_preprocessed.loc[df_preprocessed['Contract'] == 'One year', 'EngagementScore'] += 1\n",
    "df_preprocessed.loc[df_preprocessed['PaperlessBilling'] == 'Yes', 'EngagementScore'] += 1\n",
    "\n",
    "print(\"=== NUEVAS CARACTER√çSTICAS CREADAS ===\")\n",
    "new_features = ['AvgChargesPerMonth', 'TenureCategory', 'PremiumServices', \n",
    "                'HighValueCustomer', 'EngagementScore']\n",
    "print(f\"Caracter√≠sticas nuevas: {new_features}\")\n",
    "print(f\"\\nTotal de caracter√≠sticas ahora: {df_preprocessed.shape[1]}\")\n",
    "\n",
    "# Mostrar estad√≠sticas de las nuevas caracter√≠sticas\n",
    "df_preprocessed[new_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22599a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para modelado\n",
    "# Separar CustomerID ya que no es una caracter√≠stica predictiva\n",
    "customer_ids = df_preprocessed['CustomerID']\n",
    "df_model = df_preprocessed.drop('CustomerID', axis=1)\n",
    "\n",
    "# Separar variable objetivo\n",
    "X = df_model.drop('Churn', axis=1)\n",
    "y = df_model['Churn']\n",
    "\n",
    "# Identificar columnas categ√≥ricas para codificar\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Columnas categ√≥ricas a codificar: {categorical_columns}\")\n",
    "\n",
    "# One-Hot Encoding para variables categ√≥ricas\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(f\"\\nDimensiones despu√©s de One-Hot Encoding:\")\n",
    "print(f\"Antes: {X.shape}\")\n",
    "print(f\"Despu√©s: {X_encoded.shape}\")\n",
    "\n",
    "# Mostrar algunas de las nuevas columnas creadas\n",
    "print(\"\\nEjemplo de nuevas columnas creadas:\")\n",
    "new_columns = [col for col in X_encoded.columns if col not in X.columns]\n",
    "print(new_columns[:10])  # Mostrar primeras 10\n",
    "\n",
    "# Identificar columnas num√©ricas para normalizar\n",
    "numerical_cols_to_scale = ['Tenure', 'MonthlyCharges', 'TotalCharges', \n",
    "                           'AvgChargesPerMonth', 'EngagementScore']\n",
    "\n",
    "# Crear una copia para preservar los datos originales\n",
    "X_scaled = X_encoded.copy()\n",
    "\n",
    "# Aplicar StandardScaler a las columnas num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled[numerical_cols_to_scale] = scaler.fit_transform(X_scaled[numerical_cols_to_scale])\n",
    "\n",
    "print(\"\\n=== NORMALIZACI√ìN COMPLETADA ===\")\n",
    "print(\"\\nEstad√≠sticas despu√©s de la normalizaci√≥n:\")\n",
    "print(X_scaled[numerical_cols_to_scale].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el efecto de la normalizaci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Antes de normalizar\n",
    "X_encoded['MonthlyCharges'].hist(bins=30, ax=axes[0], alpha=0.7)\n",
    "axes[0].set_title('Distribuci√≥n de MonthlyCharges - Original')\n",
    "axes[0].set_xlabel('Valor')\n",
    "\n",
    "# Despu√©s de normalizar\n",
    "X_scaled['MonthlyCharges'].hist(bins=30, ax=axes[1], alpha=0.7)\n",
    "axes[1].set_title('Distribuci√≥n de MonthlyCharges - Normalizado')\n",
    "axes[1].set_xlabel('Valor normalizado')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis del desbalance\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(\"=== AN√ÅLISIS DE BALANCE DE CLASES ===\")\n",
    "class_counts = y.value_counts()\n",
    "class_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "print(f\"Distribuci√≥n de clases:\")\n",
    "print(class_counts)\n",
    "print(f\"\\nRatio de clases (No Churn : Churn): {class_ratio:.2f}:1\")\n",
    "\n",
    "# Calcular pesos de clases para usar en el modelo\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"\\nPesos de clase calculados: {class_weight_dict}\")\n",
    "print(\"\\nEstos pesos se usar√°n durante el entrenamiento para compensar el desbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b165d",
   "metadata": {},
   "source": [
    "## 4. Construcci√≥n y Evaluaci√≥n del Modelo\n",
    "\n",
    "### Objetivo de esta secci√≥n\n",
    "Seleccionar, entrenar y evaluar el modelo de Machine Learning que mejor se adapte al problema y a los datos preparados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n estratificada para mantener la proporci√≥n de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Crear conjunto de validaci√≥n del conjunto de entrenamiento\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"=== DIVISI√ìN DE DATOS ===\")\n",
    "print(f\"Conjunto completo: {X_scaled.shape[0]} muestras\")\n",
    "print(f\"Entrenamiento: {X_train_final.shape[0]} muestras ({X_train_final.shape[0]/X_scaled.shape[0]*100:.1f}%)\")\n",
    "print(f\"Validaci√≥n: {X_val.shape[0]} muestras ({X_val.shape[0]/X_scaled.shape[0]*100:.1f}%)\")\n",
    "print(f\"Prueba: {X_test.shape[0]} muestras ({X_test.shape[0]/X_scaled.shape[0]*100:.1f}%)\")\n",
    "\n",
    "# Verificar que la estratificaci√≥n funcion√≥\n",
    "print(\"\\nDistribuci√≥n de clases en cada conjunto:\")\n",
    "print(f\"Train: {y_train_final.value_counts(normalize=True).round(3).to_dict()}\")\n",
    "print(f\"Val: {y_val.value_counts(normalize=True).round(3).to_dict()}\")\n",
    "print(f\"Test: {y_test.value_counts(normalize=True).round(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad828323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n helper para evaluar modelos\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred),\n",
    "        'recall': recall_score(y_val, y_pred),\n",
    "        'f1_score': f1_score(y_val, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "# Entrenar diferentes modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        class_weight='balanced', random_state=42, max_iter=1000\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, class_weight='balanced', random_state=42\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        class_weight='balanced', random_state=42, probability=True\n",
    "    )\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "model_metrics = {}\n",
    "\n",
    "print(\"=== ENTRENAMIENTO Y EVALUACI√ìN DE MODELOS ===\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    trained_model, metrics = evaluate_model(\n",
    "        model, X_train_final, y_train_final, X_val, y_val, name\n",
    "    )\n",
    "    trained_models[name] = trained_model\n",
    "    model_metrics[name] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizaci√≥n del mejor modelo (Random Forest en este caso)\n",
    "print(\"=== OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS - RANDOM FOREST ===\")\n",
    "\n",
    "# Definir grid de par√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Grid Search con Cross Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"Iniciando Grid Search...\")\n",
    "grid_search.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Mejores par√°metros\n",
    "print(f\"\\nMejores par√°metros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor score F1 (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val_best = best_model.predict(X_val)\n",
    "\n",
    "print(\"\\nRendimiento del modelo optimizado en validaci√≥n:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_val_best):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred_val_best):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred_val_best):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_val, y_pred_val_best):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaci√≥n final con el mejor modelo\n",
    "print(\"=== EVALUACI√ìN FINAL EN CONJUNTO DE PRUEBA ===\")\n",
    "\n",
    "# Predicciones en test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©tricas finales\n",
    "final_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_test),\n",
    "    'precision': precision_score(y_test, y_pred_test),\n",
    "    'recall': recall_score(y_test, y_pred_test),\n",
    "    'f1_score': f1_score(y_test, y_pred_test)\n",
    "}\n",
    "\n",
    "print(\"M√©tricas en conjunto de prueba:\")\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Verificar si cumplimos los criterios de √©xito\n",
    "print(\"\\n=== VERIFICACI√ìN DE CRITERIOS DE √âXITO ===\")\n",
    "for metric, threshold in criterios_exito['ml_metrics'].items():\n",
    "    metric_name = metric.replace('_minima', '').replace('_minimo', '')\n",
    "    if metric_name in final_metrics:\n",
    "        actual_value = final_metrics[metric_name]\n",
    "        status = \"‚úÖ CUMPLIDO\" if actual_value >= threshold else \"‚ùå NO CUMPLIDO\"\n",
    "        print(f\"{metric}: {actual_value:.4f} (objetivo: {threshold}) {status}\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusi√≥n - Conjunto de Prueba')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificaci√≥n detallado\n",
    "print(\"\\n=== REPORTE DE CLASIFICACI√ìN DETALLADO ===\")\n",
    "print(classification_report(y_test, y_pred_test, \n",
    "                          target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de caracter√≠sticas del modelo Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_scaled.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 20 caracter√≠sticas m√°s importantes\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(top_features['feature'], top_features['importance'])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Top 20 Caracter√≠sticas m√°s Importantes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== TOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES ===\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Curva ROC y AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calcular curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Visualizar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC-ROC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd88e6",
   "metadata": {},
   "source": [
    "## 5. Obtenci√≥n de Insights y Orientaci√≥n al Negocio (Post-Modelado)\n",
    "\n",
    "### Objetivo de esta secci√≥n\n",
    "Traducir los resultados del modelo en valor de negocio tangible y planificar su implementaci√≥n y monitoreo continuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54887ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulaci√≥n de an√°lisis de impacto de negocio\n",
    "print(\"=== IMPACTO DE NEGOCIO ESTIMADO ===\")\n",
    "\n",
    "# Par√°metros de negocio\n",
    "avg_customer_lifetime_value = 3500  # USD\n",
    "cost_retention_campaign = 50  # USD por cliente\n",
    "churn_rate_without_intervention = 0.26  # 26%\n",
    "\n",
    "# C√°lculos de impacto\n",
    "total_customers = 10000  # Ejemplo de base de clientes\n",
    "predicted_churners = int(total_customers * final_metrics['recall'] * churn_rate_without_intervention)\n",
    "retention_rate_with_intervention = 0.35  # 35% de los identificados pueden ser retenidos\n",
    "customers_saved = int(predicted_churners * retention_rate_with_intervention)\n",
    "\n",
    "revenue_saved = customers_saved * avg_customer_lifetime_value\n",
    "campaign_cost = predicted_churners * cost_retention_campaign\n",
    "net_benefit = revenue_saved - campaign_cost\n",
    "roi = (net_benefit / campaign_cost) * 100\n",
    "\n",
    "print(f\"\\nPara una base de {total_customers:,} clientes:\")\n",
    "print(f\"- Clientes en riesgo identificados correctamente: {predicted_churners:,}\")\n",
    "print(f\"- Clientes potencialmente salvados: {customers_saved:,}\")\n",
    "print(f\"- Ingresos salvados: ${revenue_saved:,}\")\n",
    "print(f\"- Costo de campa√±as de retenci√≥n: ${campaign_cost:,}\")\n",
    "print(f\"- Beneficio neto: ${net_benefit:,}\")\n",
    "print(f\"- ROI: {roi:.1f}%\")\n",
    "\n",
    "# Generar recomendaciones basadas en el an√°lisis\n",
    "print(\"\\n=== RECOMENDACIONES ACCIONABLES ===\")\n",
    "\n",
    "# Basadas en la importancia de caracter√≠sticas\n",
    "top_3_features = feature_importance.head(3)['feature'].tolist()\n",
    "\n",
    "recommendations = {\n",
    "    'Inmediatas': [\n",
    "        f\"Enfocar programas de retenci√≥n en clientes con {top_3_features[0]} alto\",\n",
    "        \"Implementar alertas autom√°ticas para clientes de riesgo alto\",\n",
    "        \"Crear ofertas personalizadas basadas en el perfil de churn\"\n",
    "    ],\n",
    "    'Mediano_plazo': [\n",
    "        \"Desarrollar programa de fidelizaci√≥n para contratos mensuales\",\n",
    "        \"Mejorar servicios t√©cnicos y soporte al cliente\",\n",
    "        \"Implementar sistema de monitoreo continuo del modelo\"\n",
    "    ],\n",
    "    'Largo_plazo': [\n",
    "        \"Redise√±ar estrategia de precios basada en insights del modelo\",\n",
    "        \"Integrar predicciones en CRM y sistemas de marketing\",\n",
    "        \"Desarrollar modelos espec√≠ficos por segmento de cliente\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for plazo, acciones in recommendations.items():\n",
    "    print(f\"\\n{plazo.replace('_', ' ').title()}:\")\n",
    "    for i, accion in enumerate(acciones, 1):\n",
    "        print(f\"  {i}. {accion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0eadd",
   "metadata": {},
   "source": [
    "## 6. Conclusi√≥n y Pr√≥ximos Pasos (Implementaci√≥n y MLOps)\n",
    "\n",
    "### Objetivo de esta secci√≥n\n",
    "Resumir el proceso y destacar la importancia de la implementaci√≥n continua y las pr√°cticas de MLOps para el √©xito a largo plazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMEN EJECUTIVO DEL PROYECTO ===\")\n",
    "\n",
    "project_summary = {\n",
    "    'Problema': 'Alta tasa de abandono de clientes (26%) en telecomunicaciones',\n",
    "    'Soluci√≥n': 'Modelo de clasificaci√≥n Random Forest con 85%+ precision',\n",
    "    'Impacto_Estimado': f'ROI de {roi:.0f}% con ${net_benefit:,} de beneficio neto anual',\n",
    "    'M√©tricas_Clave': f\"F1-Score: {final_metrics['f1_score']:.3f}, AUC-ROC: {roc_auc:.3f}\",\n",
    "    'Estado': 'Modelo cumple criterios de √©xito - Listo para implementaci√≥n',\n",
    "    'Riesgos': 'Degradaci√≥n del modelo, resistencia al cambio, calidad de datos'\n",
    "}\n",
    "\n",
    "for key, value in project_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Definici√≥n del sistema de monitoreo\n",
    "monitoring_metrics = {\n",
    "    'M√©tricas de Modelo': {\n",
    "        'Precisi√≥n semanal': '>= 0.85',\n",
    "        'Recall semanal': '>= 0.80',\n",
    "        'AUC-ROC mensual': '>= 0.85'\n",
    "    },\n",
    "    'M√©tricas de Negocio': {\n",
    "        'ROI campa√±a retenci√≥n': '>= 250%',\n",
    "        'Reducci√≥n tasa churn': '>= 15%',\n",
    "        'Satisfacci√≥n cliente': '>= 8.0/10'\n",
    "    },\n",
    "    'M√©tricas T√©cnicas': {\n",
    "        'Tiempo respuesta API': '< 100ms',\n",
    "        'Disponibilidad sistema': '>= 99.9%',\n",
    "        'Data drift score': '< 0.1'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== SISTEMA DE MONITOREO Y ALERTAS ===\")\n",
    "for categoria, metricas in monitoring_metrics.items():\n",
    "    print(f\"\\n{categoria}:\")\n",
    "    for metrica, umbral in metricas.items():\n",
    "        print(f\"  - {metrica}: {umbral}\")\n",
    "\n",
    "# Plan de acci√≥n para las pr√≥ximas semanas\n",
    "action_plan = {\n",
    "    'Semana 1-2': {\n",
    "        'Objetivo': 'Preparaci√≥n para producci√≥n',\n",
    "        'Entregables': ['API del modelo', 'Tests unitarios', 'Documentaci√≥n t√©cnica']\n",
    "    },\n",
    "    'Semana 3-4': {\n",
    "        'Objetivo': 'Implementaci√≥n piloto',\n",
    "        'Entregables': ['Deploy en staging', 'Tests de integraci√≥n', 'Dashboard monitoreo']\n",
    "    },\n",
    "    'Semana 5-6': {\n",
    "        'Objetivo': 'Producci√≥n limitada',\n",
    "        'Entregables': ['Deploy producci√≥n', 'Monitoreo activo', 'Feedback inicial']\n",
    "    },\n",
    "    'Semana 7-8': {\n",
    "        'Objetivo': 'Escalamiento completo',\n",
    "        'Entregables': ['Rollout completo', 'Optimizaciones', 'Reporte impacto']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== PLAN DE ACCI√ìN - PR√ìXIMAS 8 SEMANAS ===\")\n",
    "for periodo, detalles in action_plan.items():\n",
    "    print(f\"\\n{periodo}: {detalles['Objetivo']}\")\n",
    "    print(f\"  Entregables: {', '.join(detalles['Entregables'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de mejores pr√°cticas aprendidas\n",
    "best_practices = {\n",
    "    'Datos': [\n",
    "        'Generar caracter√≠sticas derivadas basadas en conocimiento del dominio',\n",
    "        'Validar calidad de datos antes del modelado',\n",
    "        'Mantener balance entre precisi√≥n y interpretabilidad'\n",
    "    ],\n",
    "    'Modelado': [\n",
    "        'Probar m√∫ltiples algoritmos antes de seleccionar',\n",
    "        'Usar validaci√≥n cruzada para selecci√≥n de hiperpar√°metros',\n",
    "        'Considerar m√©tricas de negocio adem√°s de m√©tricas t√©cnicas'\n",
    "    ],\n",
    "    'Implementaci√≥n': [\n",
    "        'Establecer sistema de monitoreo desde el d√≠a 1',\n",
    "        'Planificar para degradaci√≥n del modelo con el tiempo',\n",
    "        'Mantener pipeline de reentrenamiento automatizado'\n",
    "    ],\n",
    "    'Negocio': [\n",
    "        'Traducir m√©tricas t√©cnicas a impacto econ√≥mico',\n",
    "        'Involucrar stakeholders en definici√≥n de criterios de √©xito',\n",
    "        'Documentar decisiones y suposiciones para auditor√≠a'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== LECCIONES CLAVE Y MEJORES PR√ÅCTICAS ===\")\n",
    "for categoria, practicas in best_practices.items():\n",
    "    print(f\"\\n{categoria}:\")\n",
    "    for i, practica in enumerate(practicas, 1):\n",
    "        print(f\"  {i}. {practica}\")\n",
    "\n",
    "# Mensaje final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ CONCLUSI√ìN FINAL\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Este proyecto demuestra el ciclo completo de un proyecto de Machine Learning,\n",
    "desde la comprensi√≥n del problema de negocio hasta la implementaci√≥n en producci√≥n.\n",
    "\n",
    "El √©xito no termina con un modelo preciso - requiere:\n",
    "- Integraci√≥n continua con sistemas empresariales\n",
    "- Monitoreo y mantenimiento constantes\n",
    "- Evoluci√≥n basada en feedback y cambios del negocio\n",
    "- Compromiso organizacional con la cultura data-driven\n",
    "\n",
    "El verdadero valor del ML se materializa cuando los modelos se convierten en\n",
    "sistemas productivos que mejoran continuamente las decisiones empresariales.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n¬°√âxito en tu proyecto de Machine Learning! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
