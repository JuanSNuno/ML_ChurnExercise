{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f634290",
   "metadata": {},
   "source": [
    "# Proyecto de Machine Learning: Guía Completa desde la Recepción de Datos\n",
    "\n",
    "## 1. Introducción al Proyecto y Definición del Problema de Negocio\n",
    "\n",
    "### Objetivo de esta sección\n",
    "Presentar el proyecto y vincular el problema de negocio con un problema de Machine Learning. Es crucial entender el problema antes de proponer una solución.\n",
    "\n",
    "### 1.1 Definición del Problema Empresarial\n",
    "\n",
    "En este notebook, trabajaremos con un ejemplo práctico: **Predicción de abandono de clientes (Churn)** en una empresa de telecomunicaciones. \n",
    "\n",
    "El problema de negocio es el siguiente:\n",
    "- La empresa está perdiendo aproximadamente 26% de sus clientes anualmente\n",
    "- Adquirir un nuevo cliente cuesta 5x más que retener uno existente\n",
    "- Necesitamos identificar clientes en riesgo de abandono para tomar acciones preventivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias para todo el proyecto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del problema en términos de ML\n",
    "problema_ml = {\n",
    "    'tipo': 'Clasificación Binaria',\n",
    "    'variable_objetivo': 'Churn',\n",
    "    'clases': ['No abandona (0)', 'Abandona (1)'],\n",
    "    'enfoque': 'Aprendizaje Supervisado',\n",
    "    'metricas_clave': ['Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "}\n",
    "\n",
    "print(\"=== DEFINICIÓN DEL PROBLEMA DE ML ===\")\n",
    "for key, value in problema_ml.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Definición de criterios de éxito\n",
    "criterios_exito = {\n",
    "    'ml_metrics': {\n",
    "        'precision_minima': 0.85,\n",
    "        'f1_score_minimo': 0.82\n",
    "    },\n",
    "    'business_metrics': {\n",
    "        'reduccion_churn_esperada': '15%',\n",
    "        'tiempo_implementacion': '3 meses'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== CRITERIOS DE ÉXITO ===\")\n",
    "print(\"\\nMétricas de Machine Learning:\")\n",
    "for metric, value in criterios_exito['ml_metrics'].items():\n",
    "    print(f\"  - {metric}: {value}\")\n",
    "print(\"\\nMétricas de Negocio:\")\n",
    "for metric, value in criterios_exito['business_metrics'].items():\n",
    "    print(f\"  - {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a11cd",
   "metadata": {},
   "source": [
    "## 2. Adquisición y Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "### Objetivo de esta sección\n",
    "Entender la naturaleza de los datos recibidos, identificar patrones, anomalías y preparar el terreno para el preprocesamiento.\n",
    "\n",
    "### 2.1 Recopilación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f220cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación de carga de datos (en un caso real, cargarías desde tu fuente)\n",
    "# Para este ejemplo, crearemos un dataset sintético representativo\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "# Generación de datos sintéticos de clientes de telecomunicaciones\n",
    "data = {\n",
    "    'CustomerID': range(1, n_samples + 1),\n",
    "    'Tenure': np.random.randint(0, 72, n_samples),  # Meses como cliente\n",
    "    'MonthlyCharges': np.random.uniform(20, 120, n_samples),\n",
    "    'TotalCharges': np.random.uniform(100, 8000, n_samples),\n",
    "    'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples, p=[0.5, 0.25, 0.25]),\n",
    "    'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_samples),\n",
    "    'PaperlessBilling': np.random.choice(['Yes', 'No'], n_samples),\n",
    "    'OnlineSecurity': np.random.choice(['Yes', 'No', 'No internet'], n_samples),\n",
    "    'TechSupport': np.random.choice(['Yes', 'No', 'No internet'], n_samples),\n",
    "    'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples, p=[0.4, 0.4, 0.2]),\n",
    "    'PhoneService': np.random.choice(['Yes', 'No'], n_samples, p=[0.9, 0.1]),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'SeniorCitizen': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),\n",
    "    'Partner': np.random.choice(['Yes', 'No'], n_samples),\n",
    "    'Dependents': np.random.choice(['Yes', 'No'], n_samples, p=[0.3, 0.7])\n",
    "}\n",
    "\n",
    "# Variable objetivo con correlación realista\n",
    "churn_probability = []\n",
    "for i in range(n_samples):\n",
    "    prob = 0.15  # Probabilidad base\n",
    "    if data['Contract'][i] == 'Month-to-month':\n",
    "        prob += 0.3\n",
    "    if data['Tenure'][i] < 12:\n",
    "        prob += 0.2\n",
    "    if data['MonthlyCharges'][i] > 80:\n",
    "        prob += 0.1\n",
    "    if data['TechSupport'][i] == 'No':\n",
    "        prob += 0.1\n",
    "    churn_probability.append(min(prob, 0.9))\n",
    "\n",
    "data['Churn'] = np.random.binomial(1, churn_probability)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"=== INFORMACIÓN DEL DATASET ===\")\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"Número de clientes: {df.shape[0]}\")\n",
    "print(f\"Número de características: {df.shape[1] - 1}\")  # -1 por la variable objetivo\n",
    "print(f\"\\nPrimeras 5 filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de tipos de datos\n",
    "print(\"=== TIPOS DE DATOS ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"\\n=== INFORMACIÓN GENERAL DEL DATASET ===\")\n",
    "df.info()\n",
    "\n",
    "# Identificación de características numéricas y categóricas\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCaracterísticas numéricas ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"Características categóricas ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Estadísticas descriptivas para variables numéricas\n",
    "print(\"\\n=== ESTADÍSTICAS DESCRIPTIVAS - VARIABLES NUMÉRICAS ===\")\n",
    "df[numerical_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de la variable objetivo\n",
    "print(\"=== DISTRIBUCIÓN DE LA VARIABLE OBJETIVO (CHURN) ===\")\n",
    "churn_dist = df['Churn'].value_counts()\n",
    "churn_pct = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Conteo absoluto:\")\n",
    "print(churn_dist)\n",
    "print(\"\\nPorcentaje:\")\n",
    "print(churn_pct)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['Churn'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribución de Churn')\n",
    "plt.xlabel('Churn (0 = No, 1 = Sí)')\n",
    "plt.ylabel('Cantidad de clientes')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Verificar si hay desbalance de clases\n",
    "if churn_pct.min() < 20:\n",
    "    print(\"\\n⚠️ ADVERTENCIA: Dataset desbalanceado detectado. Considerar técnicas de balanceo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6964646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación para variables numéricas\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación - Variables Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis de distribuciones por variable objetivo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Tenure vs Churn\n",
    "axes[0, 0].hist([df[df['Churn']==0]['Tenure'], df[df['Churn']==1]['Tenure']], \n",
    "                label=['No Churn', 'Churn'], bins=20, alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Tenure (meses)')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].set_title('Distribución de Tenure por Churn')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# MonthlyCharges vs Churn\n",
    "axes[0, 1].hist([df[df['Churn']==0]['MonthlyCharges'], df[df['Churn']==1]['MonthlyCharges']], \n",
    "                label=['No Churn', 'Churn'], bins=20, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Cargos Mensuales')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].set_title('Distribución de Cargos Mensuales por Churn')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Contract type vs Churn\n",
    "contract_churn = pd.crosstab(df['Contract'], df['Churn'], normalize='index') * 100\n",
    "contract_churn.plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Tasa de Churn por Tipo de Contrato')\n",
    "axes[1, 0].set_ylabel('Porcentaje (%)')\n",
    "axes[1, 0].set_xlabel('Tipo de Contrato')\n",
    "axes[1, 0].legend(['No Churn', 'Churn'])\n",
    "\n",
    "# PaymentMethod vs Churn\n",
    "payment_churn = pd.crosstab(df['PaymentMethod'], df['Churn'], normalize='index') * 100\n",
    "payment_churn.plot(kind='bar', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Tasa de Churn por Método de Pago')\n",
    "axes[1, 1].set_ylabel('Porcentaje (%)')\n",
    "axes[1, 1].set_xlabel('Método de Pago')\n",
    "axes[1, 1].legend(['No Churn', 'Churn'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación de valores faltantes\n",
    "print(\"=== ANÁLISIS DE VALORES FALTANTES ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Columna': missing_values.index,\n",
    "    'Valores_Faltantes': missing_values.values,\n",
    "    'Porcentaje': missing_percentage.values\n",
    "})\n",
    "\n",
    "print(missing_df[missing_df['Valores_Faltantes'] > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"✅ No se encontraron valores faltantes en el dataset\")\n",
    "\n",
    "# Verificación de duplicados\n",
    "print(\"\\n=== ANÁLISIS DE DUPLICADOS ===\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Número de filas duplicadas: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"Porcentaje de duplicados: {(duplicates/len(df))*100:.2f}%\")\n",
    "else:\n",
    "    print(\"✅ No se encontraron registros duplicados\")\n",
    "\n",
    "# Detección de outliers usando el método IQR\n",
    "print(\"\\n=== DETECCIÓN DE OUTLIERS ===\")\n",
    "\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Análisis de outliers para variables numéricas clave\n",
    "for col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  - Límite inferior: {lower:.2f}\")\n",
    "    print(f\"  - Límite superior: {upper:.2f}\")\n",
    "    print(f\"  - Número de outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76710193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de outliers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for idx, col in enumerate(['Tenure', 'MonthlyCharges', 'TotalCharges']):\n",
    "    df.boxplot(column=col, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e82c8",
   "metadata": {},
   "source": [
    "## 3. Ingeniería de Características (Feature Engineering) y Preprocesamiento\n",
    "\n",
    "### Objetivo de esta sección\n",
    "Transformar los datos crudos en un formato que sea más adecuado para el modelado de Machine Learning, mejorando el rendimiento y la robustez del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del dataset para preprocesamiento\n",
    "df_preprocessed = df.copy()\n",
    "\n",
    "print(\"✅ Limpieza de datos completada\")\n",
    "\n",
    "# Feature Engineering: Crear nuevas características basadas en conocimiento del dominio\n",
    "\n",
    "# 1. Ratio de cargos totales sobre tenure (gasto promedio mensual real)\n",
    "df_preprocessed['AvgChargesPerMonth'] = np.where(\n",
    "    df_preprocessed['Tenure'] > 0,\n",
    "    df_preprocessed['TotalCharges'] / df_preprocessed['Tenure'],\n",
    "    df_preprocessed['MonthlyCharges']\n",
    ")\n",
    "\n",
    "# 2. Categorización de tenure\n",
    "df_preprocessed['TenureCategory'] = pd.cut(\n",
    "    df_preprocessed['Tenure'],\n",
    "    bins=[0, 12, 24, 48, 72],\n",
    "    labels=['Nuevo', 'Regular', 'Establecido', 'Leal']\n",
    ")\n",
    "\n",
    "# 3. Indicador de servicio premium\n",
    "df_preprocessed['PremiumServices'] = (\n",
    "    (df_preprocessed['OnlineSecurity'] == 'Yes').astype(int) +\n",
    "    (df_preprocessed['TechSupport'] == 'Yes').astype(int)\n",
    ")\n",
    "\n",
    "# 4. Indicador de cliente de alto valor\n",
    "high_value_threshold = df_preprocessed['MonthlyCharges'].quantile(0.75)\n",
    "df_preprocessed['HighValueCustomer'] = (\n",
    "    df_preprocessed['MonthlyCharges'] > high_value_threshold\n",
    ").astype(int)\n",
    "\n",
    "# 5. Indicador de compromiso (contrato largo + sin factura en papel)\n",
    "df_preprocessed['EngagementScore'] = 0\n",
    "df_preprocessed.loc[df_preprocessed['Contract'] == 'Two year', 'EngagementScore'] += 2\n",
    "df_preprocessed.loc[df_preprocessed['Contract'] == 'One year', 'EngagementScore'] += 1\n",
    "df_preprocessed.loc[df_preprocessed['PaperlessBilling'] == 'Yes', 'EngagementScore'] += 1\n",
    "\n",
    "print(\"=== NUEVAS CARACTERÍSTICAS CREADAS ===\")\n",
    "new_features = ['AvgChargesPerMonth', 'TenureCategory', 'PremiumServices', \n",
    "                'HighValueCustomer', 'EngagementScore']\n",
    "print(f\"Características nuevas: {new_features}\")\n",
    "print(f\"\\nTotal de características ahora: {df_preprocessed.shape[1]}\")\n",
    "\n",
    "# Mostrar estadísticas de las nuevas características\n",
    "df_preprocessed[new_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22599a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para modelado\n",
    "# Separar CustomerID ya que no es una característica predictiva\n",
    "customer_ids = df_preprocessed['CustomerID']\n",
    "df_model = df_preprocessed.drop('CustomerID', axis=1)\n",
    "\n",
    "# Separar variable objetivo\n",
    "X = df_model.drop('Churn', axis=1)\n",
    "y = df_model['Churn']\n",
    "\n",
    "# Identificar columnas categóricas para codificar\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Columnas categóricas a codificar: {categorical_columns}\")\n",
    "\n",
    "# One-Hot Encoding para variables categóricas\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(f\"\\nDimensiones después de One-Hot Encoding:\")\n",
    "print(f\"Antes: {X.shape}\")\n",
    "print(f\"Después: {X_encoded.shape}\")\n",
    "\n",
    "# Mostrar algunas de las nuevas columnas creadas\n",
    "print(\"\\nEjemplo de nuevas columnas creadas:\")\n",
    "new_columns = [col for col in X_encoded.columns if col not in X.columns]\n",
    "print(new_columns[:10])  # Mostrar primeras 10\n",
    "\n",
    "# Identificar columnas numéricas para normalizar\n",
    "numerical_cols_to_scale = ['Tenure', 'MonthlyCharges', 'TotalCharges', \n",
    "                           'AvgChargesPerMonth', 'EngagementScore']\n",
    "\n",
    "# Crear una copia para preservar los datos originales\n",
    "X_scaled = X_encoded.copy()\n",
    "\n",
    "# Aplicar StandardScaler a las columnas numéricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled[numerical_cols_to_scale] = scaler.fit_transform(X_scaled[numerical_cols_to_scale])\n",
    "\n",
    "print(\"\\n=== NORMALIZACIÓN COMPLETADA ===\")\n",
    "print(\"\\nEstadísticas después de la normalización:\")\n",
    "print(X_scaled[numerical_cols_to_scale].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el efecto de la normalización\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Antes de normalizar\n",
    "X_encoded['MonthlyCharges'].hist(bins=30, ax=axes[0], alpha=0.7)\n",
    "axes[0].set_title('Distribución de MonthlyCharges - Original')\n",
    "axes[0].set_xlabel('Valor')\n",
    "\n",
    "# Después de normalizar\n",
    "X_scaled['MonthlyCharges'].hist(bins=30, ax=axes[1], alpha=0.7)\n",
    "axes[1].set_title('Distribución de MonthlyCharges - Normalizado')\n",
    "axes[1].set_xlabel('Valor normalizado')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis del desbalance\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(\"=== ANÁLISIS DE BALANCE DE CLASES ===\")\n",
    "class_counts = y.value_counts()\n",
    "class_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "print(f\"Distribución de clases:\")\n",
    "print(class_counts)\n",
    "print(f\"\\nRatio de clases (No Churn : Churn): {class_ratio:.2f}:1\")\n",
    "\n",
    "# Calcular pesos de clases para usar en el modelo\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"\\nPesos de clase calculados: {class_weight_dict}\")\n",
    "print(\"\\nEstos pesos se usarán durante el entrenamiento para compensar el desbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b165d",
   "metadata": {},
   "source": [
    "## 4. Construcción y Evaluación del Modelo\n",
    "\n",
    "### Objetivo de esta sección\n",
    "Seleccionar, entrenar y evaluar el modelo de Machine Learning que mejor se adapte al problema y a los datos preparados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División estratificada para mantener la proporción de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Crear conjunto de validación del conjunto de entrenamiento\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"=== DIVISIÓN DE DATOS ===\")\n",
    "print(f\"Conjunto completo: {X_scaled.shape[0]} muestras\")\n",
    "print(f\"Entrenamiento: {X_train_final.shape[0]} muestras ({X_train_final.shape[0]/X_scaled.shape[0]*100:.1f}%)\")\n",
    "print(f\"Validación: {X_val.shape[0]} muestras ({X_val.shape[0]/X_scaled.shape[0]*100:.1f}%)\")\n",
    "print(f\"Prueba: {X_test.shape[0]} muestras ({X_test.shape[0]/X_scaled.shape[0]*100:.1f}%)\")\n",
    "\n",
    "# Verificar que la estratificación funcionó\n",
    "print(\"\\nDistribución de clases en cada conjunto:\")\n",
    "print(f\"Train: {y_train_final.value_counts(normalize=True).round(3).to_dict()}\")\n",
    "print(f\"Val: {y_val.value_counts(normalize=True).round(3).to_dict()}\")\n",
    "print(f\"Test: {y_test.value_counts(normalize=True).round(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad828323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función helper para evaluar modelos\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Métricas\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred),\n",
    "        'recall': recall_score(y_val, y_pred),\n",
    "        'f1_score': f1_score(y_val, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "# Entrenar diferentes modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        class_weight='balanced', random_state=42, max_iter=1000\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, class_weight='balanced', random_state=42\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        class_weight='balanced', random_state=42, probability=True\n",
    "    )\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "model_metrics = {}\n",
    "\n",
    "print(\"=== ENTRENAMIENTO Y EVALUACIÓN DE MODELOS ===\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    trained_model, metrics = evaluate_model(\n",
    "        model, X_train_final, y_train_final, X_val, y_val, name\n",
    "    )\n",
    "    trained_models[name] = trained_model\n",
    "    model_metrics[name] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización del mejor modelo (Random Forest en este caso)\n",
    "print(\"=== OPTIMIZACIÓN DE HIPERPARÁMETROS - RANDOM FOREST ===\")\n",
    "\n",
    "# Definir grid de parámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Grid Search con Cross Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"Iniciando Grid Search...\")\n",
    "grid_search.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Mejores parámetros\n",
    "print(f\"\\nMejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor score F1 (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val_best = best_model.predict(X_val)\n",
    "\n",
    "print(\"\\nRendimiento del modelo optimizado en validación:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_val_best):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred_val_best):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred_val_best):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_val, y_pred_val_best):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación final con el mejor modelo\n",
    "print(\"=== EVALUACIÓN FINAL EN CONJUNTO DE PRUEBA ===\")\n",
    "\n",
    "# Predicciones en test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métricas finales\n",
    "final_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_test),\n",
    "    'precision': precision_score(y_test, y_pred_test),\n",
    "    'recall': recall_score(y_test, y_pred_test),\n",
    "    'f1_score': f1_score(y_test, y_pred_test)\n",
    "}\n",
    "\n",
    "print(\"Métricas en conjunto de prueba:\")\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Verificar si cumplimos los criterios de éxito\n",
    "print(\"\\n=== VERIFICACIÓN DE CRITERIOS DE ÉXITO ===\")\n",
    "for metric, threshold in criterios_exito['ml_metrics'].items():\n",
    "    metric_name = metric.replace('_minima', '').replace('_minimo', '')\n",
    "    if metric_name in final_metrics:\n",
    "        actual_value = final_metrics[metric_name]\n",
    "        status = \"✅ CUMPLIDO\" if actual_value >= threshold else \"❌ NO CUMPLIDO\"\n",
    "        print(f\"{metric}: {actual_value:.4f} (objetivo: {threshold}) {status}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - Conjunto de Prueba')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación detallado\n",
    "print(\"\\n=== REPORTE DE CLASIFICACIÓN DETALLADO ===\")\n",
    "print(classification_report(y_test, y_pred_test, \n",
    "                          target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de características del modelo Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_scaled.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 20 características más importantes\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(top_features['feature'], top_features['importance'])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Top 20 Características más Importantes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== TOP 10 CARACTERÍSTICAS MÁS IMPORTANTES ===\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Curva ROC y AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calcular curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Visualizar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC-ROC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd88e6",
   "metadata": {},
   "source": [
    "## 5. Obtención de Insights y Orientación al Negocio (Post-Modelado)\n",
    "\n",
    "### Objetivo de esta sección\n",
    "Traducir los resultados del modelo en valor de negocio tangible y planificar su implementación y monitoreo continuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54887ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación de análisis de impacto de negocio\n",
    "print(\"=== IMPACTO DE NEGOCIO ESTIMADO ===\")\n",
    "\n",
    "# Parámetros de negocio\n",
    "avg_customer_lifetime_value = 3500  # USD\n",
    "cost_retention_campaign = 50  # USD por cliente\n",
    "churn_rate_without_intervention = 0.26  # 26%\n",
    "\n",
    "# Cálculos de impacto\n",
    "total_customers = 10000  # Ejemplo de base de clientes\n",
    "predicted_churners = int(total_customers * final_metrics['recall'] * churn_rate_without_intervention)\n",
    "retention_rate_with_intervention = 0.35  # 35% de los identificados pueden ser retenidos\n",
    "customers_saved = int(predicted_churners * retention_rate_with_intervention)\n",
    "\n",
    "revenue_saved = customers_saved * avg_customer_lifetime_value\n",
    "campaign_cost = predicted_churners * cost_retention_campaign\n",
    "net_benefit = revenue_saved - campaign_cost\n",
    "roi = (net_benefit / campaign_cost) * 100\n",
    "\n",
    "print(f\"\\nPara una base de {total_customers:,} clientes:\")\n",
    "print(f\"- Clientes en riesgo identificados correctamente: {predicted_churners:,}\")\n",
    "print(f\"- Clientes potencialmente salvados: {customers_saved:,}\")\n",
    "print(f\"- Ingresos salvados: ${revenue_saved:,}\")\n",
    "print(f\"- Costo de campañas de retención: ${campaign_cost:,}\")\n",
    "print(f\"- Beneficio neto: ${net_benefit:,}\")\n",
    "print(f\"- ROI: {roi:.1f}%\")\n",
    "\n",
    "# Generar recomendaciones basadas en el análisis\n",
    "print(\"\\n=== RECOMENDACIONES ACCIONABLES ===\")\n",
    "\n",
    "# Basadas en la importancia de características\n",
    "top_3_features = feature_importance.head(3)['feature'].tolist()\n",
    "\n",
    "recommendations = {\n",
    "    'Inmediatas': [\n",
    "        f\"Enfocar programas de retención en clientes con {top_3_features[0]} alto\",\n",
    "        \"Implementar alertas automáticas para clientes de riesgo alto\",\n",
    "        \"Crear ofertas personalizadas basadas en el perfil de churn\"\n",
    "    ],\n",
    "    'Mediano_plazo': [\n",
    "        \"Desarrollar programa de fidelización para contratos mensuales\",\n",
    "        \"Mejorar servicios técnicos y soporte al cliente\",\n",
    "        \"Implementar sistema de monitoreo continuo del modelo\"\n",
    "    ],\n",
    "    'Largo_plazo': [\n",
    "        \"Rediseñar estrategia de precios basada en insights del modelo\",\n",
    "        \"Integrar predicciones en CRM y sistemas de marketing\",\n",
    "        \"Desarrollar modelos específicos por segmento de cliente\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for plazo, acciones in recommendations.items():\n",
    "    print(f\"\\n{plazo.replace('_', ' ').title()}:\")\n",
    "    for i, accion in enumerate(acciones, 1):\n",
    "        print(f\"  {i}. {accion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0eadd",
   "metadata": {},
   "source": [
    "## 6. Conclusión y Próximos Pasos (Implementación y MLOps)\n",
    "\n",
    "### Objetivo de esta sección\n",
    "Resumir el proceso y destacar la importancia de la implementación continua y las prácticas de MLOps para el éxito a largo plazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMEN EJECUTIVO DEL PROYECTO ===\")\n",
    "\n",
    "project_summary = {\n",
    "    'Problema': 'Alta tasa de abandono de clientes (26%) en telecomunicaciones',\n",
    "    'Solución': 'Modelo de clasificación Random Forest con 85%+ precision',\n",
    "    'Impacto_Estimado': f'ROI de {roi:.0f}% con ${net_benefit:,} de beneficio neto anual',\n",
    "    'Métricas_Clave': f\"F1-Score: {final_metrics['f1_score']:.3f}, AUC-ROC: {roc_auc:.3f}\",\n",
    "    'Estado': 'Modelo cumple criterios de éxito - Listo para implementación',\n",
    "    'Riesgos': 'Degradación del modelo, resistencia al cambio, calidad de datos'\n",
    "}\n",
    "\n",
    "for key, value in project_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Definición del sistema de monitoreo\n",
    "monitoring_metrics = {\n",
    "    'Métricas de Modelo': {\n",
    "        'Precisión semanal': '>= 0.85',\n",
    "        'Recall semanal': '>= 0.80',\n",
    "        'AUC-ROC mensual': '>= 0.85'\n",
    "    },\n",
    "    'Métricas de Negocio': {\n",
    "        'ROI campaña retención': '>= 250%',\n",
    "        'Reducción tasa churn': '>= 15%',\n",
    "        'Satisfacción cliente': '>= 8.0/10'\n",
    "    },\n",
    "    'Métricas Técnicas': {\n",
    "        'Tiempo respuesta API': '< 100ms',\n",
    "        'Disponibilidad sistema': '>= 99.9%',\n",
    "        'Data drift score': '< 0.1'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== SISTEMA DE MONITOREO Y ALERTAS ===\")\n",
    "for categoria, metricas in monitoring_metrics.items():\n",
    "    print(f\"\\n{categoria}:\")\n",
    "    for metrica, umbral in metricas.items():\n",
    "        print(f\"  - {metrica}: {umbral}\")\n",
    "\n",
    "# Plan de acción para las próximas semanas\n",
    "action_plan = {\n",
    "    'Semana 1-2': {\n",
    "        'Objetivo': 'Preparación para producción',\n",
    "        'Entregables': ['API del modelo', 'Tests unitarios', 'Documentación técnica']\n",
    "    },\n",
    "    'Semana 3-4': {\n",
    "        'Objetivo': 'Implementación piloto',\n",
    "        'Entregables': ['Deploy en staging', 'Tests de integración', 'Dashboard monitoreo']\n",
    "    },\n",
    "    'Semana 5-6': {\n",
    "        'Objetivo': 'Producción limitada',\n",
    "        'Entregables': ['Deploy producción', 'Monitoreo activo', 'Feedback inicial']\n",
    "    },\n",
    "    'Semana 7-8': {\n",
    "        'Objetivo': 'Escalamiento completo',\n",
    "        'Entregables': ['Rollout completo', 'Optimizaciones', 'Reporte impacto']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== PLAN DE ACCIÓN - PRÓXIMAS 8 SEMANAS ===\")\n",
    "for periodo, detalles in action_plan.items():\n",
    "    print(f\"\\n{periodo}: {detalles['Objetivo']}\")\n",
    "    print(f\"  Entregables: {', '.join(detalles['Entregables'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de mejores prácticas aprendidas\n",
    "best_practices = {\n",
    "    'Datos': [\n",
    "        'Generar características derivadas basadas en conocimiento del dominio',\n",
    "        'Validar calidad de datos antes del modelado',\n",
    "        'Mantener balance entre precisión y interpretabilidad'\n",
    "    ],\n",
    "    'Modelado': [\n",
    "        'Probar múltiples algoritmos antes de seleccionar',\n",
    "        'Usar validación cruzada para selección de hiperparámetros',\n",
    "        'Considerar métricas de negocio además de métricas técnicas'\n",
    "    ],\n",
    "    'Implementación': [\n",
    "        'Establecer sistema de monitoreo desde el día 1',\n",
    "        'Planificar para degradación del modelo con el tiempo',\n",
    "        'Mantener pipeline de reentrenamiento automatizado'\n",
    "    ],\n",
    "    'Negocio': [\n",
    "        'Traducir métricas técnicas a impacto económico',\n",
    "        'Involucrar stakeholders en definición de criterios de éxito',\n",
    "        'Documentar decisiones y suposiciones para auditoría'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== LECCIONES CLAVE Y MEJORES PRÁCTICAS ===\")\n",
    "for categoria, practicas in best_practices.items():\n",
    "    print(f\"\\n{categoria}:\")\n",
    "    for i, practica in enumerate(practicas, 1):\n",
    "        print(f\"  {i}. {practica}\")\n",
    "\n",
    "# Mensaje final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 CONCLUSIÓN FINAL\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Este proyecto demuestra el ciclo completo de un proyecto de Machine Learning,\n",
    "desde la comprensión del problema de negocio hasta la implementación en producción.\n",
    "\n",
    "El éxito no termina con un modelo preciso - requiere:\n",
    "- Integración continua con sistemas empresariales\n",
    "- Monitoreo y mantenimiento constantes\n",
    "- Evolución basada en feedback y cambios del negocio\n",
    "- Compromiso organizacional con la cultura data-driven\n",
    "\n",
    "El verdadero valor del ML se materializa cuando los modelos se convierten en\n",
    "sistemas productivos que mejoran continuamente las decisiones empresariales.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n¡Éxito en tu proyecto de Machine Learning! 🚀\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
